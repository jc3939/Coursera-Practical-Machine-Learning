sqrt(244.1899)/sqrt(200)
-2+1.96*sqrt(244.1899)/sqrt(200)
2-1.96*sqrt(244.1899)/sqrt(200)
s1=1.5^2
s2 = 1.8^2
n2 = 100
s1=0.5^2
s2=4
> de = (s1/n1)^2/(n1-1)+(s2/n2)^2/(n2-1)
> nu = (s1/n1+s2/n2)^2
> de = (s1/n1)^2/(n1-1)+(s2/n2)^2/(n2-1) nu = (s1/n1+s2/n2)^2
de = (s1/n1)^2/(n1-1)+(s2/n2)^2/(n2-1)
nu = (s1/n1+s2/n2)^2
nu/de
2-1.96*sqrt(111.3268)/sqrt(200)
s1=1.5^2
s2 = 1.8^2
n1=9
n2=9
de = (s1/n1)^2/(n1-1)+(s2/n2)^2/(n2-1)
nu = (s1/n1+s2/n2)^2
nu/de
-4+1.746*sqrt(15.4961)/sqrt(18)
-4+1.337*sqrt(15.4961)/sqrt(18)
-4-1.337*sqrt(15.4961)/sqrt(18)
8*s1+8*s2
(8*s1+8*s2)/16
sqrt((8*s1+8*s2)/16)/sqrt(18)
4+1.746*sqrt((8*s1+8*s2)/16)/sqrt(18)
sqrt((8*s1+8*s2)/16)/sqrt(18)
1.5^2*8+1.8^2*8
sd=sqrt(43.92/16)
sd/sqrt(18)*1.746-4
sqrt((8*s1+8*s2)/16)
a = sqrt((8*s1+8*s2)/16)
a*sqrt(1/9+1/9)
-4-1.746+a*sqrt(1/9+1/9)
-4-1.746*a*sqrt(1/9+1/9)
-4+1.746*a*sqrt(1/9+1/9)
attach(mtcars)
head(mtcars)
fit = lm(mpg~cyl+cyl*wt)
summary(fit)
fit1 = lm(mpg~cyl+wt)
summary(fit1)
summary(mtcar$cyl)
cylf = factor(cyl)
fit1 = lm(mpg~cylf+wt)
summary(fit1)
anova(fit1)
summary(mtcars$cyl)
summary(mtcars$cyl1)
anova(fit)
summary(fit1)
anova(fit1)
anova(fit)
fit = lm(mpg~cyl+wt)
summary(fit)
anova(fit)
fit1 = lm(mpg~cylf+wt)
summary(fit1)
anova(fit1)
dim(mtcars)
anova(fit)
summary(fit)
anova(fit1)
412.39/6.54
n <- 100; t <- rep(c(0, 1), c(n/2, n/2)); x <- c(runif(n/2), runif(n/2));
beta0 <- 0; beta1 <- 2; tau <- 1; sigma <- .2
y <- beta0 + x * beta1 + t * tau + rnorm(n, sd = sigma)
plot(x, y, type = "n", frame = FALSE)
abline(lm(y ~ x), lwd = 2)
abline(h = mean(y[1 : (n/2)]), lwd = 3)
abline(h = mean(y[(n/2 + 1) : n]), lwd = 3)
fit <- lm(y ~ x + t)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
coef(fit)[1]
coef(fit)[2]
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd = 3)
points(x[1 : (n/2)], y[1 : (n/2)], pch = 21, col = "black", bg = "lightblue", cex = 2)
points(x[(n/2 + 1) : n], y[(n/2 + 1) : n], pch = 21, col = "black", bg = "salmon", cex = 2)
fit2 <- lm(mpg ~ factor(cyl), mtcars)
summary(fit2)
fit1 = lm(mpg~cylf+wt)
summary(fit1)
fit3 <- lm(mpg ~ factor(cyl)*wt, mtcars)
summary(fit3)
result <- anova(fit1, fit3, test="Chi")
result$Pr
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
?I
fit4 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data=mtcars)
summary(fit4)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit5 <- lm(y ~ x)
lm.influence(fit5)$hat[5]
dfbetas(fit5)[5, 2]
x <- -5 : 5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54,
3.87, 4.97)
knotPoint <- c(0)
spline <- sapply(knotPoint, function(knot) (x > knot) * (x - knot))
xMatrix <- cbind(1, x, spline)
fit <- lm(y ~ xMatrix - 1)
yhat <- predict(fit)
yhat
slope <- fit$coef[2] + fit$coef[3]
slope # 1.013
plot(x, y)
lines(x, yhat, col=2)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(manipulate)
library(shiny)
data(airquality)
dTable(airquality, sPaginationType = "full_numbers")
library(rCharts)
dTable(airquality, sPaginationType = "full_numbers")
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
)
))
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text'),
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
)
))
shinyUI(pageWithSidebar(
headerPanel("Example plot"),
sidebarPanel(
sliderInput('mu', 'Guess at the mu',value = 70, min = 60, max = 80, step = 0.05,)
),
mainPanel(
plotOutput('newHist')
)
))
library(UsingR)
data(galton)
shinyServer(
function(input, output) {
output$myHist <- renderPlot({
hist(galton$child, xlab='child height', col='lightblue',main='Histogram')
mu <- input$mu
lines(c(mu, mu), c(0, 200),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
})
}
)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?createDataPartition
library(AppliedPredictiveModeling)
library(caret)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(ggplot2)
library(caret)
ncol(training)
which(sapply(adData,class)=="factor")
summary(training$diagnosis)
training$diagnosis = as.numeric(training$diagnosis)
p <- prcomp(training[,grep('^IL',names(training))])
p$rotation[,1:7]
qplot(1:length(p$sdev),p$sdev / sum(p$sdev))
which(cumsum(p$sdev) / sum(p$sdev) <= .9)
(cumsum(p$sdev) / sum(p$sdev))[8]
#Result here
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.9)
preProc
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.8)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(ggplot2)
library(caret)
ncol(training)
which(sapply(adData,class)=="factor")
summary(training$diagnosis)
training$diagnosis = as.numeric(training$diagnosis)
p <- prcomp(training[,grep('^IL',names(training))])
p$rotation[,1:7]
qplot(1:length(p$sdev),p$sdev / sum(p$sdev))
which(cumsum(p$sdev) / sum(p$sdev) <= .9)
(cumsum(p$sdev) / sum(p$sdev))[8]
#Result here
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.8)
preProc
tf= structure(list(state = structure(1:14, .Label = c("AK", "AL",
"AR", "AZ", "CA", "CO", "CT", "DE", "FL", "GA", "IA", "IL", "IN",
"KS"), class = "factor"), num = c(21L, 31L, 12L, 56L, 316L, 53L,
31L, 7L, 335L, 63L, 42L, 73L, 40L, 2L), region = structure(c(2L,
1L, 4L, 3L, 5L, 6L, 7L, 8L, 9L, 10L, 13L, 11L, 12L, 14L), .Label = c("alabama",
"alaska", "arizona", "arkansas", "california", "colorado", "connecticut",
"delaware", "florida", "georgia", "illinois", "indiana", "iowa",
"kansas"), class = "factor")), .Names = c("state", "num", "region"
), class = "data.frame", row.names = c(NA, -14L))
View(tf)
library(ggplot2)
library(maps)
install.packages("maps")
require(maps)
library(maps)
states <- map_data("state")
tfmerged <- merge(states, tf, sort = FALSE, by = "region")
tfmerged <- tfmerged[order(tfmerged$order), ]
qplot(long, lat, data = tfmerged, group = group, fill = num,
geom="polygon")
View(states)
View(tf)
state <- read.csv("~/Documents/state.csv", sep=";")
View(state)
states <- map_data("state")
tfmerged <- merge(states, state, sort = FALSE, by = "region")
tfmerged <- tfmerged[order(tfmerged$order), ]
qplot(long, lat, data = tfmerged, group = group, fill = num,
geom="polygon")
qplot(long, lat, data = tfmerged, group = group, fill = freq,
geom="polygon")
tfmerged <- merge(states, state, sort = FALSE, by = "region")
View(states)
View(state)
state <- read.csv("~/Documents/state.csv", sep=";")
View(state)
tfmerged <- merge(states, state, sort = FALSE, by = "region")
tfmerged <- tfmerged[order(tfmerged$order), ]
qplot(long, lat, data = tfmerged, group = group, fill = freq,
geom="polygon")
?qplot
?map_date
?map_data
View(tfmerged)
tfmerged <- tfmerged[order(tfmerged$order, decreasing = T), ]
qplot(long, lat, data = tfmerged, group = group, fill = freq,
geom="polygon")
?heatmap2
?heatmap.2
heatmap.2 {gplots}
?heatmap.2 {gplots}
library(gplots)
install.packages("gplots")
library(gplots)
?heatmap.2
?heatmap
x  <- as.matrix(mtcars)
View(x)
rc <- rainbow(nrow(x), start = 0, end = .3)
cc <- rainbow(ncol(x), start = 0, end = .3)
heatmap(x, col = cm.colors(256), scale = "column",
RowSideColors = rc, ColSideColors = cc, margins = c(5,10),
xlab = "specification variables", ylab =  "Car Models",
main = "heatmap(<Mtcars data>, ..., scale = \"column\")")
View(x)
View(tfmerged)
heatmap(long, lat, data = tfmerged, group = group, fill = freq)
qplot(long, lat, data = tfmerged, group = group, fill = freq,
geom="polygon")
qplot(long, lat, data = tfmerged, group = group,
geom="polygon")
qplot(long, lat, data = tfmerged, group = group, fill = freq,
geom="polygon")
?qplot
qplot(long, lat, data = tfmerged, group = group, fill = freq,
geom="polygon")
View(tfmerged)
qplot(long, lat, data = tfmerged, group = group, fill = "red",
geom="polygon")
library(shiny)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
library(shiny)
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
library(rChart)
library(rCharts)
library(airquality)
data(airquality)
dTable(airquality, sPaginationType = "full_numbers")
shinyUI(pageWithSidebar(
headerPanel("Example plot"),
sidebarPanel(
sliderInput('mu', 'Guess at the mu',value = 70, min = 60, max = 80, step = 0.05,)
),
mainPanel(
plotOutput('newHist')
)
))
library(UsingR)
data(galton)
shinyServer(
function(input, output) {
output$myHist <- renderPlot({
hist(galton$child, xlab='child height', col='lightblue',main='Histogram')
mu <- input$mu
lines(c(mu, mu), c(0, 200),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
})
}
)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc$rotation
clear
cls
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1
pmlTraining <- read.csv("~/Downloads/pml-training.csv")
View(pmlTraining)
setwd("~/Documents/JHU_Practical_Machine_Learning")
setwd("~/Documents/JHU_Practical_Machine_Learning/PML Project")
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
library(kernlab)
trainData <- read.csv("./data/pml-training.csv")
setwd("~/Documents/JHU_Practical_Machine_Learning/PML Project")
trainData <- read.csv("./data/pml-training.csv")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile="pml-training.csv", method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile="pml-testing.csv", method="curl")
}
if (!file.exists("pml-training.csv")) {
download.file(trainUrl, destfile="pml-training.csv", method="curl")
}
if (!file.exists("pml-testing.csv")) {
download.file(testUrl, destfile="pml-testing.csv", method="curl")
}
trainData <- read.csv("./data/pml-training.csv")
testData <- read.csv("./data/pml-testing.csv")
if (!file.exists("./data/pml-training.csv")) {
download.file(trainUrl, destfile="./data/pml-training.csv", method="curl")
}
if (!file.exists("./data/pml-testing.csv")) {
download.file(testUrl, destfile="./data/pml-testing.csv", method="curl")
}
trainData <- read.csv("./data/pml-training.csv")
testData <- read.csv("./data/pml-testing.csv")
dim(trainData)
?complete.cases
complete.cases(trainData)
View(testData)
View(trainData)
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0]
trainData <- trainData[, colSums(is.na(trainData)) == 0]
testData <- testData[, colSums(is.na(testData)) == 0]
View(testData)
View(testData)
View(trainData)
View(testData)
trainRemove <- grepl("^X|timestamp|window", names(trainData))
trainRemove
trainData <- trainData[, !trainRemove]
trainCleaned <- trainData[, sapply(trainData, is.numeric)]
sapply(trainData, is.numeric)
trainData <- read.csv("./data/pml-training.csv")
testData <- read.csv("./data/pml-testing.csv")
classe <- trainData$classe
trainData <- trainData[, colSums(is.na(trainData)) == 0]
testData <- testData[, colSums(is.na(testData)) == 0]
trainRemove <- grepl("^X|timestamp|window", names(trainData))
trainData <- trainData[, !trainRemove]
trainCleaned <- trainData[, sapply(trainData, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testData))
testData <- testRaw[, !testRemove]
testData <- testData[, !testRemove]
testCleaned <- testData[, sapply(testData, is.numeric)]
set.seed(20150927) # For reproducibile purpose
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
library(randomForest)
set.seed(20150927) # For reproducibile purpose
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
accuracy <- postResample(predictRf, testData$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(testData$classe, predictRf)$overall[1])
oose
View(testCleaned)
result <- predict(modelRf, testCleaned[, -length(names(testCleaned))])
result
ls()
if (!"modelRf" %in% ls()){
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
}
accuracy
oose
answers <- result
pml_write_files <- function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_results/problem_id_",i,".txt")
write.table(x[i], file=filename, quote=FALSE,
row.names=FALSE, col.names=FALSE)
}
}
pml_write_files(answers)
answers <- result
pml_write_files <- function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_results/problem_id_",i,".txt")
write.table(x[i], file=filename, quote=FALSE,
row.names=FALSE, col.names=FALSE)
}
}
pml_write_files(answers)
